---
title: "Machine Learning: <br><small><b>Peer Assessment - Course Project</b></small>"
author: "<a href='mailto:svicente99@yahoo.com' title='twitter:@svicente99'>Sergio Vicente</a>"
twitter: "@svicente99"
date: "May, 2015"
output: 
  html_document:
    keep_md: true
transition: fade
transition-speed: fast
subtitle: "<span style='color:#5882FA;font-size:0.8em'>Human Activity Monitoring</span>" 
---

<br><br>
You may get source code of this at <https://github.com/svicente99/MachLearn_PeerAssessment> 

And html version is available at RPubs: <http://rpubs.com/svicente99/MachLearn_Peer_Assesment>

* * * *

#### Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways [A,B,C,D,E].

#### Objective and development

The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. Any of the other variables were used to predict it. Along next sections we describe how the model was built and fitted. Two alternatives were tested: one with classification tree and another one with random forest The expected out of sample error was showed in order to advice the choice we did. Our option was **random forest** as best model fit. Finally we use this model to predict 20 different test cases. 

---------

#### Data Sourcing

The data for this assignment can be downloaded from the course web site:

* Dataset: <a href="http://groupware.les.inf.puc-rio.br/har.">Activity Data</a> [12.2 MBytes]

There is also some documentation of the database available. See above links to know how some of the variables are constructed/defined.

---------

#### Data Accquisiton

Setting parameters and files to be processed:

```{r, cache=TRUE}

# MAIN PARAMETERS
DATA_FOLDER <- "./data"  # subdirectory of current named 'data'
URL_DATA <- "http://d396qusza40orc.cloudfront.net/predmachlearn"
CSV_TRAIN <- "pml-training.csv"
CSV_TEST <- "pml-testing.csv"
# -----------------------------------------------------------------

```

Getting CSV data files and setting the main data frame (df_*):

```{r,cache=TRUE,echo=FALSE}

N_ROWS="ALL"   ## use if want to test a small part, otherwise, set to "ALL"

read_csv <- function(csv_file) 
{
  # check if the csv files are already saved ("cached") onto disk
  cached_file = paste( DATA_FOLDER, csv_file, sep = "/" );
  
  if( !file.exists(DATA_FOLDER) )  dir.create(DATA_FOLDER)
  if( !file.exists(cached_file) ) {
      url = paste(URL_DATA, csv_file, sep="/")
		  # if it is not available --> Download it !
		  downloadStatus = download.file(url, method="internal", destfile=cached_file)
      if(downloadStatus != 0)  stop("Download failed from URL: ", url)
  	  } 
  # read data from zip file already writen on disk
  if(N_ROWS=="ALL")
    df <- read.csv(cached_file)
  else
    df <- read.csv(cached_file, nrows=N_ROWS)
    
  return(df)
}

df_train <- read_csv(CSV_TRAIN)
df_test <- read_csv(CSV_TEST)

print("Dimension of training data - rows x cols")
dim(df_train)
print("Dimension of test data - rows x cols")
dim(df_test)
```

#### Packages loading

The next Libraries were used in this project. A custom function will install them (if not done yet) and will load on your "RStudio" environment.

```{r,echo=FALSE}
# function to install and load packages
pkgTest <- function(x) {
  R_repository = "http://cran.rstudio.com/"
  if( !require(x, character.only = TRUE)) {
    install.packages(x,dep=TRUE,repos=R_repository)
      if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}  
```

```{r}
# we just install and load the libraries we need to do this analysis
pkgTest("rpart")
pkgTest("rpart.plot")
pkgTest("caret")
pkgTest("rattle")
pkgTest("randomForest")
library(rpart)
library(rpart.plot)
library(caret)
library(rattle)
library(randomForest)
```

#### Data cleaning

We need to pass a good filter to clean these data up. Next function do this job.
It's not interesting to include in this analysis data containing missing values. So, get rid of them:

```{r}
clean_data <- function(df, step3=TRUE) 
{
  # get rid of columns that has only "missing values"
	df_clean <- df[, colSums(is.na(df)) == 0] 
	print(dim(df_clean))
	# then throw columns out that not participate as predictors
    vColsNotPred <- c("user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
    cols2Remove <- which(colnames(df) %in% vColsNotPred)
    df_clean <- df_clean[, -cols2Remove]	
	print(dim(df_clean))
  # the ID column (the 1st) is another that not influences our forecasting
  df_clean <- df_clean[c(-1)]
	# lastly, remove columns with zero variability
  if(step3) { ## because there is no need to 'testing' dataset ##
  	colsNear0 <- nearZeroVar(df_clean)
  	df_clean <- df_clean[, -colsNear0]
  	print(dim(df_clean))
  }
  return(df_clean)
}

df_train <- clean_data(df_train) 

summary(df_train$classe)
```

#### Spliting data in two subsets - train & test

We'll split training data set, after cleaning, in two subsets - one is a pure training data set, containing **70%** of observations and another, smaller (30%) to contain data for validation.

```{r}
set.seed(1987)      ## to may reproducible research
trainPart <- createDataPartition(df_train$classe, p=0.7, list=FALSE)
training <- df_train[+trainPart,]
testing  <- df_train[-trainPart,]
rm(trainPart)

dim(training); dim(testing)
class(training)
training$classe <- as.factor(training$classe)

# Equalizing dimensions (columns) to test data sets

nCols <- ncol(training)
colsTraining1 <- colnames(training)
colsTraining2 <- colnames(training[, -nCols])  # remove classe column (for test data set)
testing <- testing[colsTraining1]           # leave vars that are also in training set
df_test <- df_test[colsTraining2]           # leave vars that are also in training set

summary(training$classe); summary(testing$classe)
```

#### Model Fitting

We initially use 'decision tree' technique to fit a model in these data. Here are the results obtained to this adjusted model and its tree plotting.

```{r,fig.height=8,fig.width=9,echo=FALSE}
set.seed(1987)
modelFit1 <- rpart(classe ~ ., data=training, method="class")
printcp(modelFit1)

fancyRpartPlot(modelFit1, main="Decision Tree - Personal Activity - variable: classe")
box("outer", col="maroon", lwd=3) 
```

For next, we use 'random forest' algorithm to fit another model to those data. Follow the results.

```{r}
modelFit2 <- randomForest(classe ~. , data=training)
modelFit2
```

#### Predictions building and comparison

```{r}
prev1 <- predict(modelFit1, data=testing, type="class")
prev2 <- predict(modelFit2, data=testing, type="class")

tab <- table(prev1, prev2)
apply( 
  prop.table(tab,1)*100, 2, 
    function(u) sprintf( "%.1f%%", u ) 
)
```

### Using prediction model on Test data provided

```{r}

myChoiceModel <- predict(modelFit2, df_test, type="class")
myChoiceModel

# Write the result file to submission
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./data/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(myChoiceModel)
# Twenty files were saved on data folder (check it!).
```

